# Qwen Image Training - Optimal Defaults Configuration
# This file contains the recommended default values for Qwen Image training
# Supports both LoRA (parameter-efficient) and DreamBooth (full fine-tuning) modes
# Based on documentation examples and best practices

# Training Mode Selection
training_mode = "LoRA Training"  # Options: "LoRA Training" (8-16GB VRAM) or "DreamBooth Fine-Tuning" (24GB+ VRAM)

# Model Settings - REQUIRED FIELDS MUST BE SET BY USER
dit = ""  # REQUIRED: Path to DiT checkpoint (qwen_image_bf16.safetensors)
vae = ""  # REQUIRED: Path to VAE checkpoint (diffusion_pytorch_model.safetensors)
text_encoder = ""  # REQUIRED: Path to Qwen2.5-VL checkpoint
dataset_config = ""  # Path to dataset TOML configuration (required if using "Use TOML File" mode)
dataset_config_mode = "Generate from Folder Structure"  # Default to auto-generate from folder structure

# Folder Structure Settings (used when dataset_config_mode = "Generate from Folder Structure")
parent_folder_path = ""  # REQUIRED when using folder structure mode: Path to parent folder containing training images
dataset_resolution_width = 1328  # Target width for training images
dataset_resolution_height = 1328  # Target height for training images
dataset_caption_extension = ".txt"  # Extension for caption files
create_missing_captions = true  # Auto-create empty captions for images without caption files
caption_strategy = "folder_name"  # How to handle missing captions: "folder_name" or "empty"
dataset_batch_size = 1  # Batch size for dataset processing
dataset_enable_bucket = false  # Enable bucketing for variable aspect ratios
dataset_bucket_no_upscale = false  # Prevent upscaling in bucket mode
dataset_cache_directory = "cache_dir"  # Directory for caching processed data
dataset_control_directory = "edit_images"  # [EDIT MODE] Directory name for control/reference images (only used when edit=true)
dataset_qwen_image_edit_no_resize_control = false  # [EDIT MODE] Keep control images at original size. Only used when edit=true. Cannot be used with control resolution settings
dataset_qwen_image_edit_control_resolution_width = 1328  # [EDIT MODE] Control image width. 0=same as training images, 1024=official Qwen default, 1328=optimal for Qwen models. Only when edit=true
dataset_qwen_image_edit_control_resolution_height = 1328  # [EDIT MODE] Control image height. 0=same as training images, 1024=official Qwen default, 1328=optimal for Qwen models. Only when edit=true
auto_generate_black_control_images = false  # [EDIT MODE] Auto-generate pitch black PNG control images with same filenames as training images. Uses control resolution settings
generated_toml_path = ""  # Path where generated TOML will be saved (auto-set)

dit_dtype = "bfloat16"  # HARDCODED: Must be bfloat16 for Qwen Image
dit_in_channels = 16  # [DO NOT CHANGE] VAE latent channel count. MUST be 16 for Qwen (different from SD's 4). Changing breaks training!
# num_layers = 60  # [ADVANCED] Number of DiT transformer layers. Leave commented out for auto-detection (60 for standard Qwen). Uncomment and change value only for custom/pruned models
text_encoder_dtype = "bfloat16"  # Data type for Qwen2.5-VL. float16=faster, bfloat16=better precision
vae_dtype = "bfloat16"       # Data type for VAE. bfloat16=Qwen Image default, float16=faster

# VAE Optimization Settings
vae_tiling = false           # Enable spatial tiling to reduce VRAM usage during VAE operations (supported in Qwen Image)
vae_chunk_size = 0           # 0 = auto/disabled. Higher = faster but more VRAM
vae_spatial_tile_sample_min_size = 0  # 0 = disabled. 256 = typical. Auto-enables vae_tiling if set

fp8_vl = false  # Enable for GPUs with <16GB VRAM. Saves ~8GB VRAM with minimal quality loss
fp8_base = false  # Optional: FP8 for DiT model, saves ~12GB VRAM
fp8_scaled = false  # REQUIRED when fp8_base=true, better quality than standard FP8
blocks_to_swap = 0             # 0 = disabled. Max 59 (Qwen has 60 blocks). 16=save ~8GB VRAM, 45=save ~30GB VRAM (requires 64GB+ RAM)

# Additional Model Settings  
guidance_scale = 1.0          # Classifier-free guidance scale. 1.0 = default, higher = stronger prompt adherence
img_in_txt_in_offloading = false  # Memory optimization for mixed image-text inputs
edit = false  # Enable Qwen-Image-Edit mode for training with control images
edit_plus = false  # Enable Qwen-Image-Edit-2509 mode for training with multiple control images (up to 3)

# Flow Matching Settings
timestep_sampling = "qwen_shift"  # Use Qwen-specific resolution-aware sampling
discrete_flow_shift = 2.2  # Discrete flow shift for training (used with 'shift' method)
flow_shift = 7.0  # [ADVANCED] Noise schedule control. 7.0 is optimal. Higher (8-10)=smoother/slower, Lower (5-6)=faster/unstable
weighting_scheme = "none"  # Set to "mode" if you want to use mode_scale
logit_mean = 0.0
logit_std = 1.0
mode_scale = 1.0  # Optimized for Qwen (lower than SD3's 1.29 for better stability)

# Advanced Timestep Parameters (usually leave as defaults)
sigmoid_scale = 1.0          # Scale factor for sigmoid timestep sampling. Only used with 'sigmoid' method
min_timestep = 0            # 0 = no minimum constraint. 0-999 = constrain minimum timestep
max_timestep = 1000         # Maximum timestep value. 1000 = default (full range). 1-1000 = constrain maximum timestep 
preserve_distribution_shape = false  # Preserve original distribution when using min/max constraints

# Advanced Timestep Settings
num_timestep_buckets = 0  # 0 = disabled. 4-10 = bucketed sampling for uniform timestep distribution

# Debugging
show_timesteps = ""

# Training Settings
sdpa = true
flash_attn = false
sage_attn = false
xformers = false
flash3 = false               # EXPERIMENTAL: FlashAttention 3, not confirmed to work with Qwen Image
split_attn = false           # REQUIRED if using flash_attn/sage_attn/xformers/flash3
max_train_steps = 90000
max_train_epochs = 200
max_data_loader_n_workers = 2
persistent_data_loader_workers = true
seed = 99
gradient_checkpointing = true
gradient_accumulation_steps = 1
full_bf16 = false  # [EXPERIMENTAL] Store gradients in BF16. Saves ~30% VRAM but may be unstable. Monitor loss. Incompatible with mixed_precision='bf16'
full_fp16 = false  # [EXPERIMENTAL] Store gradients in FP16. Saves ~30% VRAM but risk of underflow. Use full_bf16 instead if possible

# Optimizer Settings
optimizer_type = "adamw8bit"
optimizer_args = []  # Additional optimizer arguments like ["weight_decay=0.01", "betas=0.9,0.999"]
learning_rate = 5e-5  # RECOMMENDED: Changed from 1e-4 to 5e-5 per official documentation update
max_grad_norm = 1.0
fused_backward_pass = true  # [DREAMBOOT EXCLUSIVE] Advanced memory optimization for DreamBooth fine-tuning. Automatically enabled for DreamBooth mode, disabled for LoRA mode. Requires AdaFactor optimizer. Reduces VRAM during gradient computation
lr_scheduler = "constant"
lr_warmup_steps = 0  # 0 = no warmup. Integer = steps, float <1 = ratio of total steps
lr_decay_steps = 0   # 0 = no decay. Integer = steps, float <1 = ratio of total steps
lr_scheduler_num_cycles = 1
lr_scheduler_power = 1.0
lr_scheduler_timescale = 0      # 0 = auto (uses warmup steps). Advanced parameter
lr_scheduler_min_lr_ratio = 0.0  # 0.0 = can reach zero LR. 0.1 = minimum 10% of initial LR
lr_scheduler_type = ""
lr_scheduler_args = []  # Additional scheduler arguments like ["T_max=100"]

# Network Settings (LoRA Mode Only - Ignored in DreamBooth Mode)
no_metadata = false
network_weights = ""  # [LORA ONLY] Path to pretrained LoRA weights to continue training
network_module = "networks.lora_qwen_image"  # [AUTO-SET] Set to empty for DreamBooth, networks.lora_qwen_image for LoRA
network_dim = 128  # [LORA ONLY] Network dimension/rank. RECOMMENDED: 16 per official documentation
network_alpha = 128.0  # [LORA ONLY] Alpha for scaling. RECOMMENDED: Equal to network_dim for best results
network_dropout = 0.0  # [LORA ONLY] Dropout rate. 0.0 = no dropout, 0.1 = 10% dropout for regularization
# Additional network arguments. Supported options:
# - loraplus_lr_ratio=N: Enables LoRA+ with learning rate ratio for "up" matrices (e.g., "loraplus_lr_ratio=4")
# - exclude_patterns=["regex"]: Regex patterns to exclude modules from LoRA (default excludes ".*(_mod_).*")
# - include_patterns=["regex"]: Regex patterns to re-include excluded modules
# - verbose=true: Print detailed info about which modules are being trained
# Example: ["loraplus_lr_ratio=4", "verbose=true"]
network_args = []
training_comment = ""
dim_from_weights = false
scale_weight_norms = 0.0  # 0.0 = disabled. 1.0+ = scale weights to prevent exploding gradients
base_weights = ""  # Path to LoRA weights to merge before training (empty = none)
base_weights_multiplier = 1.0  # Strength multiplier for base weights (1.0 = full strength)

# Save/Load Settings
output_dir = ""
output_name = "my-qwen-lora"  # Base filename without .safetensors extension - musubi auto-adds it
resume = ""
save_every_n_epochs = 10
save_every_n_steps = 0        # 0 = disabled. Positive integer = save every N steps
save_last_n_epochs = 0       # 0 = keep all. Positive integer = keep only last N epoch checkpoints
save_last_n_epochs_state = 0 # 0 = keep all. Positive integer = keep only last N epoch states
save_last_n_steps = 0        # 0 = keep all. Positive integer = keep only last N step checkpoints
save_last_n_steps_state = 0  # 0 = keep all. Positive integer = keep only last N step states
save_state = false
save_state_on_train_end = false
mem_eff_save = false  # [DreamBooth Only] Dramatically reduces RAM usage during checkpoint saving (from ~40GB to ~20GB). Essential for low-RAM systems doing DreamBooth fine-tuning. Ignored for LoRA training. NOTE: Optimizer state saves still require full RAM

# Caching Settings - Latents
caching_latent_device = "cuda"
caching_latent_batch_size = 4
caching_latent_num_workers = 8
caching_latent_skip_existing = true
caching_latent_keep_cache = true
caching_latent_debug_mode = ""
caching_latent_console_width = 80
caching_latent_console_back = ""
caching_latent_console_num_images = 0  # 0 = no limit. Positive integer = max images in debug console

# Caching Settings - Text Encoder
caching_teo_text_encoder = ""
caching_teo_device = "cuda"
caching_teo_fp8_vl = false
caching_teo_batch_size = 16
caching_teo_num_workers = 8
caching_teo_skip_existing = true
caching_teo_keep_cache = true

# Accelerate Launch Settings
mixed_precision = "bf16"    # RECOMMENDED for Qwen Image. fp16 may cause instability, fp8 not supported
multi_gpu = false           # Enable distributed multi-GPU training
gpu_ids = "0"                # GPU IDs for distributed training (e.g., "0,1,2,3")
num_processes = 1           # Number of processes for distributed training
num_machines = 1            # Number of machines for distributed training
num_cpu_threads_per_process = 2  # CPU threads per process
main_process_port = 0       # Port for distributed training communication (0 = auto)
dynamo_backend = "no"       # no = disabled (recommended). Use inductor for PyTorch 2.0+ optimization
dynamo_mode = ""            # Empty = default. Options: "default", "reduce-overhead", "max-autotune"
dynamo_use_fullgraph = false   # Use fullgraph mode for dynamo
dynamo_use_dynamic = false     # Use dynamic mode for dynamo
extra_accelerate_launch_args = ""  # Additional accelerate launch arguments

# Logging Settings
logging_dir = ""
# log_with = ""  # Leave commented out or set to specific logger like "tensorboard"
log_prefix = ""
log_tracker_name = ""
wandb_run_name = ""
log_tracker_config = ""
wandb_api_key = ""
log_config = false

# DDP Settings
ddp_timeout = 0  # 0 = use default (30min). Positive integer = timeout in minutes for distributed training
ddp_gradient_as_bucket_view = false
ddp_static_graph = false

# Sample Generation
# Generate sample images during training to monitor progress
sample_every_n_steps = 0   # 0 = disabled. 100-500 recommended for step-based sampling
sample_every_n_epochs = 0  # 0 = disabled. 1 = generate samples every epoch (recommended)
sample_at_first = false
sample_prompts = ""  # Path to text file with prompts for sample generation

# Default Sample Parameters
# These will be automatically added to prompts that don't specify them
# An enhanced prompt file will be saved to your output directory
sample_width = 1328                # Default width (Qwen optimal: 1328)
sample_height = 1328               # Default height (Qwen optimal: 1328)
sample_steps = 20                  # Number of denoising steps
sample_guidance_scale = 1.0        # Guidance scale (higher = stronger prompt adherence)
sample_seed = 99                   # Random seed (-1 = random each time)
sample_discrete_flow_shift = 2.2     # Discrete flow shift (0 = use training value, 2.2 = Qwen optimal)
sample_cfg_scale = 1.0             # CFG scale for negative prompt (1.0 = disabled)
sample_negative_prompt = ""        # Default negative prompt for all samples

# Metadata Settings
metadata_author = ""
metadata_description = ""
metadata_license = ""
metadata_tags = ""
metadata_title = ""

# HuggingFace Settings
huggingface_repo_id = ""
huggingface_token = ""
huggingface_repo_type = ""
huggingface_repo_visibility = ""
huggingface_path_in_repo = ""
save_state_to_huggingface = false
resume_from_huggingface = false
async_upload = false